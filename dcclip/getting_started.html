<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PQEPB7QH14"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-PQEPB7QH14');
    </script>
    
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="In search of the next generation of multimodal datasets" />
    <meta name="author" content="Sarah Pratt" />

    <title>DataComp</title>

    <!-- Favicon -->
    <link rel="shortcut icon" href="../assets/images/corner.png" type="image/x-icon">

    <!-- Added Libraries -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/boxicons@latest/css/boxicons.min.css"
    />
    <link rel="stylesheet"
        href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <!-- StyleSheets -->
    <link rel="stylesheet" href="../assets/css/style.css" />

  </head>
  <body>

    <!-- Header Part Start -->
    <!-- Header Part Start -->
    <header class="header">
      <nav class="nav container">
        <a href="../index.html" class="nav__logo">  DataComp </a>
        <div class="nav__menu">
          <ul class="nav__list">
            <li class="nav__item">
              <a href="./index.html#home" class="nav__link">Home</a>
            </li>
            <li class="nav__item">
              <a href="./index.html#participate" class="nav__link">Participate</a>
            </li>
            <li class="nav__item">
              <a href="./index.html#tracks" class="nav__link">Track</a>
            </li>
            <li class="nav__item">
              <a href="./index.html#faqs" class="nav__link">FAQs</a>
            </li>
            <!-- <li class="nav__item">
              <a href="./leaderboard.html#leaderboard" class="nav__link">Leaderboard</a>
            </li> -->
            <li class="nav__item">
              <a href="./workshop.html#first" class="nav__link">Workshop</a>
            </li>
            <li class="nav__item">
              <a href="./people.html#group" class="nav__link">Team</a>
            </li>
          </ul>
        </div>
        <div class="ham__btn">
          <i class="bx bx-grid-alt"></i>
        </div>
        <a href="./leaderboard.html" class="btn btn__header">Leaderboard</a>
      </nav>
    </header>
    <!-- Header Part End -->
    <!-- Header Part End -->



    <!-- Main content body start  -->
    <main class="main">
      <!-- Home  -->

      
      
      <div class="container" id="first">
        <!-- <div align="center" style="padding-top:10rem;">
          <img width="100%" src="./assets/images/svgs/workshop.svg">
          </div> -->

        <div class="group grid-small-pad">
            <h3 class="workshop__title" align="left" style="padding-top:5rem;"> Getting Started </h3>
		
        <h3> Overview </h3>
		<p class="home__desc" style="clear: left">
           DataComp is a competition about designing multimodal datasets.
            As a participant, your task is to create a pre-training dataset with image-text pairs that produces a CLIP model high accuracy on downstream tasks.
            Unlike traditional benchmarks, in DataComp the model architecture and hyperparameters are fixed, and your task is to innovate on the dataset design.
            As part of the benchmark, we provide CommonPool, a large collection of 12.8B image-text pairs crawled from the public internet.

            Our benchmark offers two tracks: one where participants must use only samples from the pools we provide (filtering), and another where participants can use external data, including samples from our pool (Bring your own data, BYOD).
            DataComp is designed to accommodate verious levels of computational resources: each track is broken down into four scales, spanning several orders of magnitude of compute.
        
            <br><br>
            Our codebase is available at <a href="https://github.com/mlfoundations/datacomp" target="_blank">github.com/mlfoundations/datacomp</a>.
        </p>

        <h3> Install dependencies </h3>
        <p style="clear: left;">To start, clone the repository and install the dependencies.</p>
        <pre><code class="hljs language-bash">conda env create -f environment.yml</code></pre>
        <p style="clear:left;">To activate the environment:</p>
        <pre><code class="hljs language-bash">conda activate datacomp</code></pre>
        <br>
        
        <h3> Downloding CommonPool </h3>

        <p style="clear: left;">To download CommonPool, run the following command, replacing <code>$scale</code> with the competition scale (i.e. <code>small</code>, <code>medium</code>, <code>large</code> or <code>xlarge</code>) and <code>$data_dir</code> with the output directory where you want the data to be stored.
        <pre><code class="hljs language-bash">python download_upstream.py --scale $scale --data_dir $data_dir</code></pre>
        <p style="clear: left;">There are four scales in our competition:</p>
        <ul class="disc">
            <li><code>small</code>: 12.8M pool size, 12.8M examples seen</li>
            <li><code>medium</code>: 128M pool size, 128M examples seen</li>
            <li><code>large</code>: 1.28B pool size, 1.28B examples seen</li>
            <li><code>xlarge</code>: 12.8B pool size, 12.8B examples seen</li>
        </ul>
        <p style="clear: left;">
            The data is stored in shards, which are tar files with the images and captions to be consumed by <a href="https://github.com/webdataset/webdataset/" target="_blank">webdataset</a>.
            Once the download finishes, the data will be available at <code>$data_dir/shards</code>.
            We offer options for selecting subsets of the downloaded pool <a href="https://github.com/mlfoundations/datacomp/blob/master/README.md#selecting-samples-in-the-filtering-track" target="_blank">here</a>.
        </p>
        <br>

        <h3>Training</h3>
        <p style="clear: left;">
            To train, run the following command:
        </p>
        

        <pre><code class="hljs language-bash">torchrun --nproc_per_node $num_gpus train.py --scale $scale --data_dir $data_dir --output_dir $output_dir --exp_name $exp_name</code></pre>

        <br>
        <h3>Evaluating</h3>

        <p style="clear: left;">
            To evaluate, run the following command:
        </p>

        <pre><code class="hljs language-bash">python evaluate.py  --train_output_dir $train_output_dir/$exp_name</code></pre>
        <br>
    
        <h3>Submitting</h3>
        <p style="clear: left; padding-bottom:10rem">
            See our <a href="https://github.com/mlfoundations/datacomp/blob/master/README.md#submitting" target="_blank">submission instructions</a>. Good luck!
        </p>

        </div>
		
		
    </div>
	
	<div align="center" style="padding-bottom:1rem;">
	<img width="80%" src="../assets/images/svgs/logo.svg">
	</div>

		

    </main>
    <!-- Main content body end  -->

    <!-- Footer start  -->
    <footer class="section" id="footer">
      <div class="footer container grid">

      <!-- <p class="footer__copy">
        &#169; Developed by Shahidul Alam. Designed by Bedimcode. (Inspired)
      </p> -->
    </footer>
    <!-- Footer end  -->

    <!-- Scroll to top button -->
    <a href="#" class="scrollup" id="scroll-up">
      <i class="bx bx-up-arrow-alt scrollup__icon"></i>
    </a>


    <!-- Javascript -->
    <script src="../assets/js/main.js"></script>
  </body>
</html>
